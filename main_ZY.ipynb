{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T14:31:55.000928Z",
     "start_time": "2025-01-04T14:31:54.979872Z"
    }
   },
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/flore/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:31:58.613615Z",
     "start_time": "2025-01-04T14:31:58.607653Z"
    }
   },
   "cell_type": "code",
   "source": "party_mapping = {'ELDR': 0, 'GUE-NGL': 1, 'PPE-DE': 2, 'PSE': 3, 'Verts-ALE': 4}",
   "id": "35e8a9357f77e201",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:31:59.552665Z",
     "start_time": "2025-01-04T14:31:59.546216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pretrait_texte(texte):\n",
    "    texte = texte.lower()\n",
    "    texte = ''.join([char for char in texte if char not in string.punctuation])\n",
    "    return texte"
   ],
   "id": "839a4c1d3969b465",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:00.718904Z",
     "start_time": "2025-01-04T14:32:00.709783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_xml(file_path, is_train=True):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    textes = []\n",
    "    labels = []\n",
    "    text_id = {}\n",
    "\n",
    "    for doc in root.findall('.//doc'):\n",
    "        doc_id = int(doc.attrib['id'].split(\":\")[-1]) - 1\n",
    "        texte = \" \".join([p.text.replace('\\xa0', '') for p in doc.findall('.//texte/p') if p.text is not None])\n",
    "        texte = pretrait_texte(texte)\n",
    "        textes.append(texte)\n",
    "        text_id[texte] = doc_id\n",
    "\n",
    "        if is_train:\n",
    "            label = doc.find('.//PARTI').attrib['valeur']\n",
    "            labels.append(party_mapping[label])\n",
    "\n",
    "    if is_train:\n",
    "        return textes, labels, text_id\n",
    "\n",
    "    return textes, text_id"
   ],
   "id": "719c025eec9d89b9",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:02.002674Z",
     "start_time": "2025-01-04T14:32:01.996193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_reference(file_path, test_dict, X_test):\n",
    "    references = {}\n",
    "    valid_textes = []\n",
    "    valid_labels = []\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            partis = line.strip().split('\\t')\n",
    "            if len(partis) < 2 or partis[1] not in party_mapping:\n",
    "                print(f\"Skipping line: {line.strip()}\")\n",
    "                continue\n",
    "\n",
    "            ref_id = int(partis[0]) - 1\n",
    "            if ref_id in test_dict.values():\n",
    "                references[ref_id] = party_mapping[partis[1]]\n",
    "\n",
    "    for texte in X_test:\n",
    "        if test_dict[texte] in references:\n",
    "            valid_textes.append(texte)\n",
    "            valid_labels.append(references[test_dict[texte]])\n",
    "\n",
    "    return valid_textes, valid_labels"
   ],
   "id": "8bf1853fb860eaa1",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Corpus anglais",
   "id": "d233b8f8845dc367"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:08.376803Z",
     "start_time": "2025-01-04T14:32:04.715202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file = './Corpus d_apprentissage/deft09_parlement_appr_en.xml'\n",
    "X_train, y_train, train_dict = parse_xml(train_file, is_train=True)\n",
    "\n",
    "test_file = './Corpus de test/deft09_parlement_test_en.xml'\n",
    "X_test, test_dict = parse_xml(test_file, is_train=False)\n",
    "\n",
    "ref_file = './Données de référence/deft09_parlement_ref_en.txt'\n",
    "X_test, y_test = parse_reference(ref_file, test_dict, X_test)"
   ],
   "id": "98e71428e7051737",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line: 2602\n",
      "Skipping line: 12172\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:08.384973Z",
     "start_time": "2025-01-04T14:32:08.383140Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(X_test), len(y_test))",
   "id": "1a817b873c22bf94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12913 12913\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:13.121989Z",
     "start_time": "2025-01-04T14:32:09.856575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ],
   "id": "73aca8d26ebd52a0",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:16.034617Z",
     "start_time": "2025-01-04T14:32:13.913383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# liste de modèles\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "11a93235f94c1e6c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74      1339\n",
      "           1       0.84      0.78      0.81      1792\n",
      "           2       0.74      0.83      0.79      4570\n",
      "           3       0.72      0.74      0.73      3627\n",
      "           4       0.79      0.67      0.73      1585\n",
      "\n",
      "    accuracy                           0.76     12913\n",
      "   macro avg       0.79      0.74      0.76     12913\n",
      "weighted avg       0.77      0.76      0.76     12913\n",
      "\n",
      "Evaluating model: Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.72      0.74      1339\n",
      "           1       0.84      0.78      0.81      1792\n",
      "           2       0.79      0.81      0.80      4570\n",
      "           3       0.75      0.78      0.76      3627\n",
      "           4       0.75      0.72      0.74      1585\n",
      "\n",
      "    accuracy                           0.78     12913\n",
      "   macro avg       0.78      0.76      0.77     12913\n",
      "weighted avg       0.78      0.78      0.78     12913\n",
      "\n",
      "Evaluating model: SGDClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.47      0.59      1339\n",
      "           1       0.75      0.72      0.74      1792\n",
      "           2       0.61      0.85      0.71      4570\n",
      "           3       0.69      0.56      0.62      3627\n",
      "           4       0.77      0.50      0.61      1585\n",
      "\n",
      "    accuracy                           0.67     12913\n",
      "   macro avg       0.72      0.62      0.65     12913\n",
      "weighted avg       0.69      0.67      0.66     12913\n",
      "\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Corpus français",
   "id": "ca49eaee6f18bca8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:31.520846Z",
     "start_time": "2025-01-04T14:32:27.304215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file = './Corpus d_apprentissage/deft09_parlement_appr_fr.xml'\n",
    "X_train, y_train, train_dict = parse_xml(train_file, is_train=True)\n",
    "\n",
    "test_file = './Corpus de test/deft09_parlement_test_fr.xml'\n",
    "X_test, test_dict = parse_xml(test_file, is_train=False)\n",
    "\n",
    "ref_file = './Données de référence/deft09_parlement_ref_fr.txt'\n",
    "X_test, y_test = parse_reference(ref_file, test_dict, X_test)"
   ],
   "id": "f43aabb1b620721b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line: 1175\n",
      "Skipping line: 4574\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:31.529768Z",
     "start_time": "2025-01-04T14:32:31.526548Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(X_test), len(y_test))",
   "id": "124d439e489a025d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12915 12915\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:35.525144Z",
     "start_time": "2025-01-04T14:32:31.595248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "french_stopwords = stopwords.words('french')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=french_stopwords)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ],
   "id": "fe438826e467db7d",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:32:43.746576Z",
     "start_time": "2025-01-04T14:32:41.374949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# liste de modèles\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "d0ab1d0f2d4a4143",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73      1339\n",
      "           1       0.85      0.82      0.83      1793\n",
      "           2       0.76      0.84      0.80      4571\n",
      "           3       0.74      0.76      0.75      3627\n",
      "           4       0.82      0.70      0.76      1585\n",
      "\n",
      "    accuracy                           0.78     12915\n",
      "   macro avg       0.80      0.76      0.77     12915\n",
      "weighted avg       0.78      0.78      0.78     12915\n",
      "\n",
      "Evaluating model: Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      1339\n",
      "           1       0.85      0.79      0.82      1793\n",
      "           2       0.79      0.82      0.81      4571\n",
      "           3       0.75      0.77      0.76      3627\n",
      "           4       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.78     12915\n",
      "   macro avg       0.78      0.76      0.77     12915\n",
      "weighted avg       0.78      0.78      0.78     12915\n",
      "\n",
      "Evaluating model: SGDClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.45      0.59      1339\n",
      "           1       0.72      0.78      0.75      1793\n",
      "           2       0.62      0.87      0.72      4571\n",
      "           3       0.72      0.57      0.64      3627\n",
      "           4       0.83      0.51      0.63      1585\n",
      "\n",
      "    accuracy                           0.69     12915\n",
      "   macro avg       0.75      0.64      0.67     12915\n",
      "weighted avg       0.71      0.69      0.68     12915\n",
      "\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Corpus italien",
   "id": "22668c52b02d71ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:15.637402Z",
     "start_time": "2025-01-04T14:33:10.656439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file = './Corpus d_apprentissage/deft09_parlement_appr_it.xml'\n",
    "X_train, y_train, train_dict = parse_xml(train_file, is_train=True)\n",
    "\n",
    "test_file = './Corpus de test/deft09_parlement_test_it.xml'\n",
    "X_test, test_dict = parse_xml(test_file, is_train=False)\n",
    "\n",
    "ref_file = './Données de référence/deft09_parlement_ref_it.txt'\n",
    "X_test, y_test = parse_reference(ref_file, test_dict, X_test)"
   ],
   "id": "8ab998cec41640d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping line: 1239\n",
      "Skipping line: 8634\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:33:25.798223Z",
     "start_time": "2025-01-04T14:33:25.779633Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(X_test), len(y_test))",
   "id": "d250152084596f8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12915 12915\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:34:24.949284Z",
     "start_time": "2025-01-04T14:34:20.991156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "italian_stopwords = stopwords.words('italian')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=italian_stopwords)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ],
   "id": "14fe20296493ce5d",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T14:34:27.242290Z",
     "start_time": "2025-01-04T14:34:24.963238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# liste de modèles\n",
    "\n",
    "models = {\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'Perceptron': Perceptron(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating model: {model_name}\")\n",
    "    clf = model\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n"
   ],
   "id": "37ac8f65c2be7764",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: LinearSVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73      1339\n",
      "           1       0.86      0.79      0.82      1793\n",
      "           2       0.76      0.84      0.80      4571\n",
      "           3       0.75      0.78      0.76      3627\n",
      "           4       0.80      0.69      0.74      1585\n",
      "\n",
      "    accuracy                           0.78     12915\n",
      "   macro avg       0.80      0.75      0.77     12915\n",
      "weighted avg       0.78      0.78      0.78     12915\n",
      "\n",
      "Evaluating model: Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71      1339\n",
      "           1       0.82      0.79      0.80      1793\n",
      "           2       0.80      0.81      0.80      4571\n",
      "           3       0.76      0.78      0.77      3627\n",
      "           4       0.73      0.70      0.72      1585\n",
      "\n",
      "    accuracy                           0.77     12915\n",
      "   macro avg       0.76      0.75      0.76     12915\n",
      "weighted avg       0.77      0.77      0.77     12915\n",
      "\n",
      "Evaluating model: SGDClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.47      0.60      1339\n",
      "           1       0.74      0.75      0.75      1793\n",
      "           2       0.64      0.85      0.73      4571\n",
      "           3       0.70      0.62      0.66      3627\n",
      "           4       0.79      0.51      0.62      1585\n",
      "\n",
      "    accuracy                           0.69     12915\n",
      "   macro avg       0.74      0.64      0.67     12915\n",
      "weighted avg       0.71      0.69      0.69     12915\n",
      "\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a12c1daefb73349e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
