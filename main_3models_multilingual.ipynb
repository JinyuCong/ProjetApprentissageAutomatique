{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Importing Necessary Libraries\n",
                "This section imports the libraries required for processing the data and training models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import xml.etree.ElementTree as ET\n",
                "import numpy as np\n",
                "import string\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.metrics import classification_report\n",
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.linear_model import Perceptron, SGDClassifier"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Helper Functions\n",
                "This section defines functions for data extraction, processing, and cleaning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_text_party_pairs(file_path: str) -> np.ndarray:\n",
                "    with open(file_path, encoding=\"utf-8\") as file:\n",
                "        xml_string = file.read()\n",
                "    root = ET.fromstring(xml_string)\n",
                "    pairs = []\n",
                "    for doc in root.findall('.//doc'):\n",
                "        parti_elem = doc.find('.//PARTI')\n",
                "        if parti_elem is not None:\n",
                "            party = parti_elem.get('valeur')\n",
                "            text_elem = doc.find('.//texte')\n",
                "            if text_elem is not None:\n",
                "                paragraphs = [p.text for p in text_elem.findall('p') if p.text]\n",
                "                full_text = ' '.join(paragraphs)\n",
                "                pairs.append([full_text, party])\n",
                "    return np.array(pairs, dtype=str)\n",
                "\n",
                "def extract_text_pairs_without_party(file_path: str) -> np.ndarray:\n",
                "    with open(file_path, encoding=\"utf-8\") as file:\n",
                "        xml_string = file.read()\n",
                "    root = ET.fromstring(xml_string)\n",
                "    texts = []\n",
                "    for doc in root.findall('.//doc'):\n",
                "        text_elem = doc.find('.//texte')\n",
                "        if text_elem is not None:\n",
                "            paragraphs = [p.text for p in text_elem.findall('p') if p.text]\n",
                "            full_text = ' '.join(paragraphs)\n",
                "            texts.append(full_text)\n",
                "    return np.array(texts, dtype=str)\n",
                "\n",
                "def load_reference_labels(file_path: str) -> np.ndarray:\n",
                "    with open(file_path, encoding=\"utf-8\") as file:\n",
                "        labels = [line.strip() for line in file.readlines()]\n",
                "    return np.array(labels, dtype=str)\n",
                "\n",
                "def remove_punctuation(text):\n",
                "    return ''.join(char.lower() for char in text if char not in string.punctuation)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Defining Dataset Paths and Models\n",
                "This section specifies the paths to the datasets for English, French, and Italian and defines the models for evaluation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "party_mapping = {\n",
                "    \"ELDR\": 0,\n",
                "    \"GUE-NGL\": 1,\n",
                "    \"PPE-DE\": 2,\n",
                "    \"PSE\": 3,\n",
                "    \"Verts-ALE\": 4\n",
                "}\n",
                "\n",
                "datasets = {\n",
                "    \"en\": {\n",
                "        \"train\": \"./Corpus d_apprentissage/deft09_parlement_appr_en.xml\",\n",
                "        \"test\": \"./Corpus de test/deft09_parlement_test_en.xml\",\n",
                "        \"reference\": \"./Données de référence/deft09_parlement_ref_en.txt\"\n",
                "    },\n",
                "    \"fr\": {\n",
                "        \"train\": \"./Corpus d_apprentissage/deft09_parlement_appr_fr.xml\",\n",
                "        \"test\": \"./Corpus de test/deft09_parlement_test_fr.xml\",\n",
                "        \"reference\": \"./Données de référence/deft09_parlement_ref_fr.txt\"\n",
                "    },\n",
                "    \"it\": {\n",
                "        \"train\": \"./Corpus d_apprentissage/deft09_parlement_appr_it.xml\",\n",
                "        \"test\": \"./Corpus de test/deft09_parlement_test_it.xml\",\n",
                "        \"reference\": \"./Données de référence/deft09_parlement_ref_it.txt\"\n",
                "    }\n",
                "}\n",
                "\n",
                "models = {\n",
                "    \"LinearSVC\": LinearSVC(),\n",
                "    \"Perceptron\": Perceptron(),\n",
                "    \"SGDClassifier\": SGDClassifier()\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training and Evaluating Models\n",
                "This section loops through each language and evaluates multiple models for classification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing language: EN\n",
                        "Ignored line: 2602\n",
                        "Ignored line: 12172\n",
                        "Evaluating model: LinearSVC for language: EN\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.93      0.69      0.80      1339\n",
                        "     GUE-NGL       0.90      0.81      0.85      1793\n",
                        "      PPE-DE       0.76      0.90      0.82      4571\n",
                        "         PSE       0.79      0.79      0.79      3627\n",
                        "   Verts-ALE       0.89      0.70      0.78      1585\n",
                        "\n",
                        "    accuracy                           0.81     12915\n",
                        "   macro avg       0.85      0.78      0.81     12915\n",
                        "weighted avg       0.82      0.81      0.81     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: Perceptron for language: EN\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.81      0.74      0.77      1339\n",
                        "     GUE-NGL       0.85      0.81      0.83      1793\n",
                        "      PPE-DE       0.80      0.85      0.82      4571\n",
                        "         PSE       0.80      0.79      0.79      3627\n",
                        "   Verts-ALE       0.78      0.74      0.76      1585\n",
                        "\n",
                        "    accuracy                           0.80     12915\n",
                        "   macro avg       0.81      0.79      0.80     12915\n",
                        "weighted avg       0.80      0.80      0.80     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: SGDClassifier for language: EN\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.93      0.68      0.79      1339\n",
                        "     GUE-NGL       0.87      0.82      0.84      1793\n",
                        "      PPE-DE       0.73      0.92      0.81      4571\n",
                        "         PSE       0.82      0.75      0.79      3627\n",
                        "   Verts-ALE       0.91      0.68      0.78      1585\n",
                        "\n",
                        "    accuracy                           0.80     12915\n",
                        "   macro avg       0.85      0.77      0.80     12915\n",
                        "weighted avg       0.82      0.80      0.80     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Processing language: FR\n",
                        "Ignored line: 1175\n",
                        "Ignored line: 4574\n",
                        "Evaluating model: LinearSVC for language: FR\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.92      0.66      0.77      1339\n",
                        "     GUE-NGL       0.89      0.83      0.86      1793\n",
                        "      PPE-DE       0.76      0.90      0.82      4571\n",
                        "         PSE       0.78      0.79      0.79      3627\n",
                        "   Verts-ALE       0.90      0.70      0.79      1585\n",
                        "\n",
                        "    accuracy                           0.81     12915\n",
                        "   macro avg       0.85      0.78      0.81     12915\n",
                        "weighted avg       0.82      0.81      0.81     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: Perceptron for language: FR\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.82      0.69      0.75      1339\n",
                        "     GUE-NGL       0.80      0.84      0.82      1793\n",
                        "      PPE-DE       0.79      0.86      0.82      4571\n",
                        "         PSE       0.80      0.76      0.78      3627\n",
                        "   Verts-ALE       0.76      0.74      0.75      1585\n",
                        "\n",
                        "    accuracy                           0.79     12915\n",
                        "   macro avg       0.80      0.78      0.78     12915\n",
                        "weighted avg       0.80      0.79      0.79     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: SGDClassifier for language: FR\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.94      0.63      0.76      1339\n",
                        "     GUE-NGL       0.83      0.83      0.83      1793\n",
                        "      PPE-DE       0.72      0.92      0.81      4571\n",
                        "         PSE       0.81      0.72      0.76      3627\n",
                        "   Verts-ALE       0.92      0.67      0.78      1585\n",
                        "\n",
                        "    accuracy                           0.79     12915\n",
                        "   macro avg       0.85      0.75      0.79     12915\n",
                        "weighted avg       0.81      0.79      0.79     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Processing language: IT\n",
                        "Ignored line: 1239\n",
                        "Ignored line: 8634\n",
                        "Evaluating model: LinearSVC for language: IT\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.93      0.65      0.77      1339\n",
                        "     GUE-NGL       0.89      0.81      0.85      1793\n",
                        "      PPE-DE       0.76      0.89      0.82      4571\n",
                        "         PSE       0.78      0.80      0.79      3627\n",
                        "   Verts-ALE       0.89      0.69      0.77      1585\n",
                        "\n",
                        "    accuracy                           0.80     12915\n",
                        "   macro avg       0.85      0.77      0.80     12915\n",
                        "weighted avg       0.82      0.80      0.80     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: Perceptron for language: IT\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.79      0.69      0.73      1339\n",
                        "     GUE-NGL       0.84      0.81      0.82      1793\n",
                        "      PPE-DE       0.78      0.85      0.82      4571\n",
                        "         PSE       0.79      0.78      0.78      3627\n",
                        "   Verts-ALE       0.77      0.72      0.74      1585\n",
                        "\n",
                        "    accuracy                           0.79     12915\n",
                        "   macro avg       0.79      0.77      0.78     12915\n",
                        "weighted avg       0.79      0.79      0.79     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n",
                        "Evaluating model: SGDClassifier for language: IT\n",
                        "              precision    recall  f1-score   support\n",
                        "\n",
                        "        ELDR       0.94      0.64      0.76      1339\n",
                        "     GUE-NGL       0.84      0.82      0.83      1793\n",
                        "      PPE-DE       0.72      0.91      0.81      4571\n",
                        "         PSE       0.80      0.74      0.77      3627\n",
                        "   Verts-ALE       0.91      0.66      0.77      1585\n",
                        "\n",
                        "    accuracy                           0.79     12915\n",
                        "   macro avg       0.85      0.76      0.79     12915\n",
                        "weighted avg       0.81      0.79      0.79     12915\n",
                        "\n",
                        "--------------------------------------------------------------------------------\n"
                    ]
                }
            ],
            "source": [
                "for lang, paths in datasets.items():\n",
                "    print(f\"Processing language: {lang.upper()}\")\n",
                "    \n",
                "    train_data = extract_text_party_pairs(paths[\"train\"])\n",
                "    if len(train_data) == 0:\n",
                "        raise ValueError(f\"Training data is empty for {lang}. Please check the training file format.\")\n",
                "    X_train = train_data[:, 0]\n",
                "    y_train = train_data[:, 1]\n",
                "    \n",
                "    test_data = extract_text_pairs_without_party(paths[\"test\"])\n",
                "    if len(test_data) == 0:\n",
                "        raise ValueError(f\"Testing data is empty for {lang}. Please check the test file format.\")\n",
                "    X_test = test_data\n",
                "    \n",
                "    # Load and clean reference labels\n",
                "    y_reference = load_reference_labels(paths[\"reference\"])\n",
                "    y_reference_cleaned = []\n",
                "    X_test_aligned = []\n",
                "    for text, line in zip(X_test, y_reference):\n",
                "        if line.strip() and '\\t' in line:  # Check if line is valid\n",
                "            try:\n",
                "                party_label = line.split('\\t')[1].strip()\n",
                "                if party_label in party_mapping:\n",
                "                    y_reference_cleaned.append(party_label)\n",
                "                    X_test_aligned.append(text)\n",
                "                else:\n",
                "                    print(f\"Unknown party label: {party_label}\")\n",
                "            except IndexError:\n",
                "                print(f\"Malformed line: {line}\")\n",
                "        else:\n",
                "            print(f\"Ignored line: {line}\")\n",
                "    \n",
                "    # Ensure the cleaned data is consistent\n",
                "    if len(X_test_aligned) != len(y_reference_cleaned):\n",
                "        raise ValueError(\"Aligned test data and reference labels have inconsistent lengths.\")\n",
                "\n",
                "    y_train_encoded = np.array([party_mapping[label] for label in y_train])\n",
                "    y_reference_encoded = np.array([party_mapping[label] for label in y_reference_cleaned])\n",
                "    \n",
                "    # Vectorize the text data\n",
                "    vectorizer = TfidfVectorizer(preprocessor=remove_punctuation, stop_words='english', max_df=0.9, ngram_range=(1, 2))\n",
                "    X_train_transformed = vectorizer.fit_transform(X_train)\n",
                "    X_test_transformed = vectorizer.transform(X_test_aligned)\n",
                "    \n",
                "    # Train and evaluate each model\n",
                "    for model_name, model in models.items():\n",
                "        print(f\"Evaluating model: {model_name} for language: {lang.upper()}\")\n",
                "        model.fit(X_train_transformed, y_train_encoded)\n",
                "        y_pred = model.predict(X_test_transformed)\n",
                "        print(classification_report(y_reference_encoded, y_pred, target_names=list(party_mapping.keys())))\n",
                "        print(\"-\" * 80)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
